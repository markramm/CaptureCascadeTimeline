---
date: '2017-03-20'
title: YouTube Serves Ads on Terror, Hate, Child Exploitation Content; Massive Boycott
description: A Times of London investigation revealed that advertisements from major brands and the British government were appearing on YouTube videos supporting ISIS, featuring white supremacist David Duke, promoting terrorism, and containing hate speech. The investigation triggered a massive advertiser boycott with over 250 companies including AT&T, Johnson & Johnson, PepsiCo, Walmart pulling advertising from YouTube. The British government immediately suspended all YouTube advertising after discovering taxpayer-funded ads next to ISIS content. The scandal exposed YouTube's complete failure to prevent ad monetization of extremist content despite promising "brand safety." Google's Chief Business Officer apologized and promised fixes, but the problems continued for years—demonstrating that YouTube prioritized advertising revenue over preventing the monetization of terrorism and hate speech. Analysts estimated Google could lose up to $750 million from the boycott.
actors:
- YouTube
- Google
- Times of London
- Major advertisers (AT&T, PepsiCo, Johnson & Johnson, Walmart, etc.)
- British government
- Philip Schindler (Google Chief Business Officer)
importance: 9
tags:
- youtube
- advertising
- terrorism
- hate-speech
- brand-safety
- advertiser-boycott
- isis
- content-moderation-failure
sources:
- title: Companies are boycotting YouTube because their ads are showing up next to hate-filled and extremist videos
  url: https://www.cbc.ca/radio/day6/episode-331-barkley-marathons-youtube-boycott-debit-cards-for-famine-aid-2004-red-sox-champs-and-more-1.4045494/companies-are-boycotting-youtube-because-their-ads-are-showing-up-next-to-hate-filled-and-extremist-videos-1.4045499
  outlet: CBC Radio
  date: '2017-03-25'
- title: Google to Revamp Ad Policies After U.K., Big Brands Boycott
  url: https://www.bloomberg.com/news/articles/2017-03-17/u-k-pulls-ads-from-youtube-citing-failures-in-policing-content
  outlet: Bloomberg
  date: '2017-03-17'
- title: After YouTube boycott, Google pulls ads from more types of offensive content
  url: https://techcrunch.com/2017/03/21/after-youtube-boycott-google-pulls-ads-from-more-types-of-offensive-content/
  outlet: TechCrunch
  date: '2017-03-21'
- title: '#Adpocalypse / YouTube Advertiser Boycott'
  url: https://knowyourmeme.com/memes/events/adpocalypse-youtube-advertiser-boycott
  outlet: Know Your Meme
  date: '2017-03-20'
status: confirmed
id: 2017-03-20--youtube-ads-on-terrorism-hate-content
capture_lanes:
- Corporate Negligence
- Terrorism Financing
- Hate Speech Amplification
capture_type: corporate_negligence
patterns:
- monetizing-extremism
- brand-safety-failure
- advertising-on-terrorism
- inadequate-moderation
connections:
- YouTube radicalization algorithm
- Monetization of extremist content
- Platform accountability failures
notes: Known as the "Adpocalypse." YouTube's monetization of ISIS and hate content showed platform prioritized ad revenue over preventing terrorism financing. Boycott forced temporary policy changes but structural problems remained.
---

On March 17-20, 2017, a Times of London investigation exposed that major brands' advertisements were appearing on YouTube videos supporting terrorism, promoting hate speech, and featuring extremist content—triggering the largest advertiser boycott in digital platform history and exposing YouTube's systematic failure to prevent monetization of dangerous content.

## The Times of London Investigation

The Times revealed that advertisements run by the British government, major corporations, and charitable organizations were appearing on YouTube videos including:

- **ISIS supporters and terrorist propaganda**
- **White supremacist content** featuring David Duke (former KKK leader)
- **Holocaust denial videos**
- **Antisemitic conspiracy theories**
- **Homophobic hate speech**
- **Videos promoting terrorism and violence**

The placement was not rare or accidental—the investigation found widespread, systematic ad placement on extremist content across thousands of videos.

## How YouTube Monetized Extremism

YouTube's business model created the problem:

### The Revenue System
1. **Content creators** upload videos (including extremists)
2. **YouTube's algorithm** recommends videos to maximize watch time
3. **Ads appear** before/during popular videos
4. **Revenue split**: YouTube takes 45%, creator receives 55%
5. **Result**: Terrorists and extremists literally **earn money** from YouTube

### Brand Safety Failure

YouTube promised "brand safety"—ensuring ads wouldn't appear next to objectionable content. The Times investigation proved these promises were false:

- Major brands appeared next to ISIS propaganda
- Government ads funded extremist content creators
- Hate speech channels received advertising revenue
- YouTube's automated systems completely failed to prevent extremist monetization

## The Advertiser Response: Mass Exodus

Within days of the Times investigation, over 250 major companies and organizations pulled advertising from YouTube:

### Major Brands That Suspended Advertising
- AT&T
- Verizon
- Johnson & Johnson
- PepsiCo
- Walmart
- Starbucks
- General Motors
- Enterprise Rent-A-Car
- GSK (pharmaceuticals)
- HSBC (banking)
- Lloyds Banking Group
- Royal Bank of Scotland
- Marks & Spencer
- The Guardian newspaper
- BBC

### Government Responses

**United Kingdom**: The British government immediately suspended all YouTube advertising after discovering taxpayer funds were inadvertently supporting extremist content

**Other governments**: Multiple government entities globally reviewed their YouTube advertising policies

## Financial Impact

Financial analysts estimated the boycott could cost Google:

- **Nomura Instinet estimate**: Up to $750 million in lost advertising revenue
- **Short-term impact**: Significant advertiser departures through Q2 2017
- **Long-term damage**: Brand reputation harm and advertiser hesitancy
- **Stock impact**: Alphabet shares declined on boycott news

While Google ultimately survived the boycott, it represented the largest advertiser revolt in digital advertising history.

## YouTube's Response

Google Chief Business Officer Philip Schindler issued a blog post stating:

"We know that this is unacceptable to the advertisers and agencies who put their trust in us. That's why we've been conducting an extensive review of our advertising policies and tools, and why we made a public commitment last week to put in place changes that give brands more control over where their ads appear."

### Promised Changes

YouTube announced several policy changes:

1. **Stricter content guidelines** for monetization eligibility
2. **Improved automated detection** of extremist content
3. **Manual review expansion** for flagged videos
4. **Brand safety controls** allowing advertisers to exclude content categories
5. **Transparency tools** showing where ads appeared

### The Problem: Promises Without Enforcement

While YouTube announced policy changes, implementation was minimal:

- **Automated detection remained inadequate** for identifying extremist content
- **Manual review couldn't scale** to YouTube's volume (500 hours uploaded per minute)
- **Revenue incentives unchanged**: YouTube still profited from extremist engagement
- **Problems continued**: Similar scandals emerged repeatedly in subsequent years

## Why YouTube Failed to Prevent the Problem

Multiple factors explain YouTube's systematic failure:

### Revenue Prioritization
YouTube profited from extremist content through:
- Ad revenue on popular extremist videos
- Watch time from extremist rabbit holes
- User engagement from controversial content

Preventing monetization of extremism would reduce revenue—creating incentives to under-enforce.

### Scale Challenges
- **500 hours of video uploaded per minute** (720,000 hours/day)
- **Automated systems struggled** to understand context, sarcasm, coded language
- **Human review couldn't scale** to check every video for brand safety
- **Extremists evolved tactics** to evade detection (coded language, slightly altered content)

### Information Asymmetry
- Advertisers couldn't see where ads appeared in real-time
- YouTube controlled all placement data
- Brand safety promises were unverifiable
- Only investigative journalism exposed the problem

### Inadequate Investment
Despite billions in revenue, YouTube underinvested in:
- Content moderation staff
- Automated detection systems
- Brand safety infrastructure
- Proactive extremism prevention

## The Monetization of Terrorism

The most disturbing aspect: YouTube's system **financially rewarded terrorists and extremists**.

### How ISIS Supporters Earned Money
1. Upload propaganda videos to YouTube
2. YouTube algorithm recommends to interested users
3. Ads appear on videos
4. ISIS supporters receive 55% of ad revenue
5. Money funds further extremist content

This created perverse incentives where terrorism-adjacent content was **profitable** for creators, encouraging more extremist uploads.

### Advertiser Complicity
Companies inadvertently funded extremism:
- AT&T ads → revenue to white supremacists
- Disney ads → revenue to ISIS supporters
- Government ads → taxpayer money to hate groups

No advertiser intentionally funded extremism, but YouTube's broken system made it inevitable.

## Pattern of Repeated Failures

The 2017 boycott wasn't isolated—it was part of ongoing brand safety failures:

**2016**: Initial reports of ads on extremist content (largely ignored)
**2017**: Times investigation triggers mass boycott
**2018**: Advertisers discover ads on conspiracy theories, child exploitation
**2019**: Second major boycott over pedophile exploitation (Matt Watson investigation)
**2020+**: Continued issues with COVID misinformation monetization

Each scandal followed the same pattern:
1. Investigation exposes monetization of harmful content
2. Advertisers revolt
3. YouTube promises fixes
4. Problems continue with new forms of harmful content

## The "Adpocalypse" Effect on Creators

YouTube's response to the boycott had unintended consequences for legitimate creators:

**Demonetization wave**: YouTube aggressively demonetized videos to reassure advertisers

**Arbitrary enforcement**: Automated systems flagged innocent content as "not advertiser-friendly"

**Revenue collapse**: Many small creators lost income as YouTube over-corrected

**Inconsistent rules**: Major outlets and extremists often kept monetization while small creators lost it

This created a paradox: YouTube hurt small creators while often continuing to monetize more problematic content from large channels.

## Inadequate Policy Changes

YouTube's post-boycott changes were insufficient:

### What Didn't Work

**Automated detection**: Still couldn't reliably identify extremist content in context
**Manual review**: Too slow and inconsistent for platform scale
**Creator self-certification**: Extremists simply lied about content
**Keyword blocking**: Extremists used coded language to evade

### Structural Problems Remained

- **Revenue model unchanged**: YouTube still profited from extremist engagement
- **Algorithm unchanged**: Continued recommending extremist content for watch time
- **Insufficient investment**: Content moderation budget tiny compared to platform revenue
- **No real accountability**: No penalties for monetizing terrorism beyond temporary PR crises

## Legal and Regulatory Questions

The scandal raised legal questions YouTube largely avoided:

**Terrorism financing**: Did ad revenue to ISIS supporters constitute material support for terrorism?
**Platform liability**: Should platforms face liability for monetizing illegal content?
**Duty of care**: Do platforms have responsibility to prevent monetization of extremism?
**Advertiser rights**: Can companies sue for brand damage from appearing next to extremist content?

YouTube successfully avoided legal liability, arguing Section 230 immunity and lack of knowledge about specific videos' content.

## Comparison to Other Platforms

YouTube's brand safety problems were worse than competitors:

**Facebook**: Better automated detection, faster extremist content removal
**Twitter**: More aggressive suspensions of terrorist accounts
**TikTok**: Stricter pre-moderation preventing extremist uploads
**YouTube**: Largest scale, worst enforcement, most extremist monetization

## Long-Term Impact

The 2017 boycott forced some improvements but failed to solve structural issues:

**Positive changes**:
- Increased investment in content moderation
- Better advertiser controls
- More transparency about placements
- Stricter monetization requirements

**Persistent problems**:
- Extremist content still uploaded and monetized
- Algorithm still amplifies controversial content
- Scale continues to overwhelm moderation
- Revenue incentives unchanged

## Significance for Platform Accountability

The 2017 YouTube advertiser boycott demonstrated several critical principles:

**Economic pressure works**: Only when advertisers threatened revenue did YouTube act

**Self-regulation fails**: YouTube had years to prevent the problem but only acted under external pressure

**Transparency is essential**: Only investigative journalism revealed what advertisers' own tools couldn't detect

**Regulation may be necessary**: Voluntary brand safety clearly insufficient to prevent monetization of terrorism and hate

The scandal established that platforms would continue monetizing dangerous content unless forced by advertiser boycotts, media exposure, or regulatory intervention—voluntary ethics and policies were insufficient when they conflicted with revenue maximization.

YouTube's monetization of terrorism and hate speech exemplified how engagement-optimized platforms inevitably amplify harmful content because such content generates watch time and advertising revenue—making regulation potentially necessary to prioritize public safety over platform profits.
