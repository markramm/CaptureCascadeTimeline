---
id: 2021-01-15--predpol-rebrands-geolitica-amid-criticism
date: 2021-01-15
title: PredPol Rebrands as Geolitica Amid Mounting Criticism of Racial Bias
importance: 7
tags:
  - surveillance
  - technology
  - ai
  - police
  - civil-rights
actors:
  - PredPol
  - Geolitica
sources:
  - url: https://en.wikipedia.org/wiki/Geolitica
    title: Geolitica
    publisher: Wikipedia
    date: 2024-01-01
    tier: 2
  - url: https://www.techpolicy.press/politicians-move-to-limit-predictive-policing-after-years-of-controversial-failures/
    title: Politicians Move to Limit Predictive Policing After Years of Controversial Failures
    publisher: TechPolicy.Press
    date: 2021-08-01
    tier: 2
  - url: https://themarkup.org/prediction-bias/2023/10/02/predictive-policing-software-terrible-at-predicting-crimes
    title: Predictive Policing Software Terrible At Predicting Crimes
    publisher: The Markup
    date: 2023-10-02
    tier: 1
---

PredPol, the controversial predictive policing software company, rebrands itself as Geolitica in 2021 as criticism of algorithmic bias in law enforcement intensifies. The rebrand represents an attempt to distance the company from growing scrutiny of predictive policing's discriminatory impacts and documented failures to reduce crime.

The rebrand follows years of mounting evidence that PredPol's algorithms disproportionately direct police officers to patrol neighborhoods with relatively higher percentages of low-income, Black, and Latino residents. Critics and academics have demonstrated that because the PredPol algorithm relies on historical crime data reflecting decades of racially biased policing, it reproduces and reinforces those discriminatory patterns rather than providing objective predictions.

Despite the name change, Geolitica continues producing the same predictive policing software that ingests data from crime incident reports and generates daily predictions on where and when crimes are most likely to occur. The technology's fundamental methodology remains unchanged, as do its structural problems with bias and accuracy.

The company's accuracy claims face particular scrutiny during this period. An examination of 23,631 predictions generated by Geolitica for the Plainfield Police Department between February 25 and December 18, 2018 finds an abysmal success rate of less than half a percentâ€”fewer than 100 predictions aligned with crimes in the predicted category that were later reported to police. This represents a 99.5% failure rate.

Scholar Ruha Benjamin characterizes PredPol as a "crime production algorithm," highlighting how the technology creates a self-fulfilling prophecy: police officers more heavily patrol predicted crime zones while expecting to find criminal activity, which leads to increased arrests in those areas, which the algorithm then uses to validate its predictions. This cycle perpetuates over-policing of communities of color under the guise of data-driven objectivity.

Significantly, no independent published research has ever confirmed PredPol's or Geolitica's claims about the software's accuracy or crime-reduction effectiveness, as noted by Smithsonian magazine in 2018. The company's marketing relies on testimonials and internally generated statistics rather than peer-reviewed validation.

The rebrand proves insufficient to rescue the failing business model. In an August 2023 earnings call, the CEO of SoundThinking (formerly ShotSpotter) announces that his company has begun absorbing parts of Geolitica, including its engineering team, patents, and customer contracts. Geolitica ceases operations at the end of 2023, marking the effective end of one of the most prominent predictive policing companies.

The rise and fall of PredPol/Geolitica illustrates the dangers of deploying algorithmic systems trained on biased data in law enforcement contexts, and the importance of independent evaluation of technologies that significantly impact civil liberties.
