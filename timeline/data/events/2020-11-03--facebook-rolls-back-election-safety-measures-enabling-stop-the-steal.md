---
id: 2020-11-03--facebook-rolls-back-election-safety-measures-enabling-stop-the-steal
date: '2020-11-03'
title: 'Facebook Rolls Back Election Safety Measures Immediately After 2020 Vote, Enabling "Stop the Steal" Misinformation'
importance: 10
actors:
- Facebook
- Mark Zuckerberg
- Frances Haugen
- Donald Trump
- Civic Integrity Team
tags:
- facebook
- election-manipulation
- january-6
- misinformation
- algorithm-harm
- stop-the-steal
- 2020-election
- frances-haugen
- whistleblower
- civic-integrity
sources:
- title: 'Ex-Facebook manager alleges social network fed Capitol riot'
  url: https://www.npr.org/2021/10/03/1042908136/facebook-whistleblower-frances-haugen-social-network-capitol-riot
  outlet: NPR
  date: '2021-10-03'
  tier: 1
- title: "How 'Stop the Steal' outwitted Facebook ahead of Jan. 6"
  url: https://www.npr.org/2021/10/22/1048543513/facebook-groups-jan-6-insurrection
  outlet: NPR
  date: '2021-10-22'
  tier: 1
- title: 'How Facebook is Misleading Public About Its Role in January 6'
  url: https://www.justsecurity.org/78494/how-facebook-is-misleading-the-public-about-its-role-in-january-6/
  outlet: Just Security
  date: '2021-10-14'
  tier: 1
- title: "Facebook Papers paint damning picture of company's role in insurrection"
  url: https://www.cnn.com/2021/10/22/business/january-6-insurrection-facebook-papers/index.html
  outlet: CNN
  date: '2021-10-22'
  tier: 2
status: confirmed
capture_lanes:
- Algorithmic Violence
- Election Manipulation
- Insurrection Facilitation
- Corporate Negligence
---

Facebook dismantles election safety measures immediately after the 2020 vote, prematurely rolling back safeguards designed to combat misinformation despite internal warnings. The decision enables "Stop the Steal" conspiracy theories to spread virally through the platform's algorithmic amplification, directly contributing to the January 6 Capitol insurrection.

## Premature Rollback of Safety Measures

Within days of the November 3, 2020 election, Facebook began systematically dismantling the safety measures it had implemented to prevent election misinformation from spreading. These "levers" - guardrails designed to slow the spread of hate speech, misinformation, and violent content - were prematurely turned off despite clear evidence that election-related misinformation was intensifying rather than subsiding.

Internal Facebook documents labeled these protections as "US2020 Levers" and showed they were systematically rolled back in the post-election period. Frances Haugen, a data scientist who worked on Facebook's Civic Integrity team, later testified that Facebook "chose profits over safety" by removing these safeguards before the transition of power was complete, despite knowing that the post-election period posed heightened risks for violence-inciting content.

The rollback decision was made even as internal research showed that misinformation about election fraud was spreading at unprecedented rates on the platform. A November 2020 internal document stated: "Not only do we not do something about combustible election misinformation in comments, we amplify them and give them broader distribution." Rather than maintain heightened protections during the dangerous post-election period, Facebook prioritized engagement and ad revenue over public safety.

## Algorithm Amplification of "Stop the Steal" Movement

With safety measures disabled, Facebook's engagement-maximizing algorithm proactively amplified the "Stop the Steal" conspiracy movement, treating election fraud misinformation as highly engaging content that kept users on the platform. The algorithm's recommendation systems pushed Stop the Steal content to users who had never searched for it, creating viral spread of organizing efforts for the January 6 insurrection.

Internal documents revealed that Facebook knew its algorithms were promoting harmful election misinformation but "failed to deploy internally-recommended or lasting counter-measures." The company's civic integrity researchers repeatedly warned leadership that the algorithm was amplifying content inciting violence around false election fraud claims, but their recommendations were overruled in favor of maintaining engagement metrics.

Facebook proved fundamentally unprepared for how the Stop the Steal movement used its platform for insurrection organizing. Internal analysis found that Facebook "treated each piece of Stop the Steal content individually rather than as a cohesive movement," allowing coordinated organizing for violence to evade detection. By the time Facebook took systematic action against Stop the Steal groups, the movement had already organized the logistics for the January 6 Capitol attack.

## Civic Integrity Team Disbanded

Shortly after the 2020 election, Facebook dissolved its Civic Integrity team entirely - the specialized unit responsible for preventing the platform from being used to undermine democratic elections. The team had been studying how Facebook's algorithms could be exploited for election manipulation and had developed recommendations for preventing post-election violence.

Frances Haugen, who worked on the Civic Integrity team, later testified that disbanding the team in the immediate post-election period "helped encourage the January 6 riots." The dissolution sent a clear signal that election integrity was no longer a priority for Facebook leadership once the election was over, despite the team's warnings that the post-election period posed the highest risk for violence-inciting misinformation.

The timing of the dissolution was particularly damaging because the Civic Integrity team had institutional knowledge about Stop the Steal organizing patterns and had identified the specific mechanisms through which Facebook's algorithm was amplifying insurrection-planning content. Disbanding the team eliminated the internal expertise needed to counter these threats during the critical post-election period.

## Securities Fraud and Investor Deception

In SEC complaints filed by Haugen, she alleged that "Facebook misled investors and the public about its role perpetuating misinformation and violent extremism relating to the 2020 election and January 6th insurrection." The company's public statements claimed robust election integrity measures while internal documents showed systematic rollback of protections and algorithmic amplification of violence-inciting content.

Facebook's decision to prioritize engagement over safety in the post-election period represented a knowing choice to enable misinformation that executives understood posed risks of political violence. Internal documents show that Facebook had the technical capability and institutional knowledge to prevent its platform from becoming an organizing tool for insurrection, but chose not to deploy available countermeasures to avoid reducing engagement metrics.

The company's failure to maintain election safety measures directly contributed to the January 6 Capitol attack, where rioters who organized through Facebook groups attempted to prevent the peaceful transfer of presidential power. Facebook's algorithmic amplification of election fraud conspiracies created the coordinated belief structure that motivated the insurrection, demonstrating how surveillance capitalism business models create systematic incentives for enabling political violence.
